## Autoregressive Predictive Coding
This repository contains the official implementation (in PyTorch) of the Autoregressive Predictive Coding (APC) model proposed in [An Unsupervised Autoregressive Model for Speech Representation Learning](https://arxiv.org/abs/1904.03240).

APC is a speech feature extractor trained on a large amount of unlabeled data. With an unsupervised, autoregressive training objective, representations learned by APC not only capture general acoustic characteristics such as speaker and phone information from the speech signals, but are also highly accessible to downstream models--our experimental results on phone classification show that a linear classifier taking the APC representations as the input features significantly outperforms a multi-layer percepron using the surface features.

=== 10/29/2019 update ===
Our new paper entitled [Generative Pre-Training for Speech with Autoregressive Predictive Coding](https://arxiv.org/abs/1910.12607) is now online. In this work we study the transferability of APC representations to a wide range of downstream speech tasks, including speech recognition, speech translation, and speaker identification. We also compare the effectiveness of RNN and Transformer as the backbone architecture for training APC. Code will be added to this repository upon acceptance.

## Dependencies
* Python 3.5
* PyTorch 1.0

## Dataset
In the paper, we used the train-clean-360 split from the [LibriSpeech](http://www.openslr.org/12/) corpus for training the APC models, and the dev-clean split for keeping track of the training loss. We used the log Mel spectrograms, which were generated by running the Kaldi scripts, as the input acoustic features to the APC models. Of course you can generate the log Mel spectrograms yourself, but to help you better reproduce our results, here we provide the links to the data proprocessed by us that can be directly fed to the APC models. We also include other data splits that we did not use in the paper for you to explore, e.g., you can try training an APC model on a larger and nosier set (e.g., train-other-500) and see if it learns more robust speech representations.
* [train-clean-100](https://www.dropbox.com/s/kl6ivulhucukdz1/train-clean-100.xz?dl=0)
* [train-clean-360](https://www.dropbox.com/s/0hzg2momellrpoj/train-clean-360.xz?dl=0) (used for training APC models in our paper)
* [train-other-500](https://www.dropbox.com/s/uy0aex30ufq2po8/train-other.xz?dl=0)
* [dev-clean](https://www.dropbox.com/s/4f1ypyowwmkfapx/dev-clean.xz?dl=0) (used for tracing the training loss)

## Training APC
Below we will follow the paper and use train-clean-360 and dev-clean as demonstration. Once you have downloaded the data, unzip them by running:
```bash
xz -d train-clean-360.xz
xz -d dev-clean.xz
```
Then, create a directory `librispeech_data/kaldi` and move the data into it:
```bash
mkdir -p librispeech_data/kaldi
mv train-clean-360-hires-norm.blogmel librispeech_data/kaldi
mv dev-clean-hires-norm.blogmel librispeech_data/kaldi
```
Now we will have to transform the data into the format loadable by the PyTorch DataLoader. To do so, simply run:
```bash
# Prepare the training set
python prepare_data.py --librispeech_from_kaldi librispeech_data/kaldi/train-clean-360-hires-norm.blogmel --save_dir librispeech_data/preprocessed/train-clean-360-hires-norm.blogmel
# Prepare the valication set
python prepare_data.py --librispeech_from_kaldi librispeech_data/kaldi/dev-clean-hires-norm.blogmel --save_dir librispeech_data/preprocessed/dev-clean-hires-norm-blogmel
```
Once the program is done, you will see a directory `preprocessed/` inside `librispeech_data/` that contains all the preprocessed PyTorch tensors.

To train an APC model, simply run:
```bash
python train_apc.py
```
By default, the trained models will be put in `logs/`. You can also use Tensorboard to trace the training progress. There are many other configurations you can try, check `train_apc.py` for more details--it is highly documented and should be self-explanatory.

## Feature extraction
Once you have trained your APC model, you can use it to extract speech features from your target dataset. To do so, feed-forward the trained model on the target dataset and retrieve the extracted features by running:
```bash
_, feats = model.forward(inputs, lengths)
```
`feats` is a PyTorch tensor of shape (`num_layers`, `batch_size`, `seq_len`, `rnn_hidden_size`) where:
- `num_layers` is the RNN depth of your APC model
- `batch_size` is your inference batch size
- `seq_len` is the maximum sequence length and is determined when you run `prepare_data.py`. By default this value is 1600.
- `rnn_hidden_size` is the dimensionality of the RNN hidden unit.

As you can see, `feats` is essentially the RNN hidden states in an APC model. You can think of APC as a speech version of [ELMo](https://www.aclweb.org/anthology/N18-1202) if you are familiar with it.

There are many ways to incorporate `feats` into your downstream task. One of the easiest way is to take only the outputs of the last RNN layer (i.e., `feats[-1, :, :, :]`) as the input features to your downstream model, which is what we did in our paper. Feel free to explore other mechanisms.

## Reference
Please cite our paper(s) if you find this repository useful. Cite both if you are kind enough!
```
@inproceedings{chung2019unsupervised,
  title = {An unsupervised autoregressive model for speech representation learning},
  author = {Chung, Yu-An and Hsu, Wei-Ning and Tang, Hao and Glass, James},
  booktitle = {Interspeech},
  year = {2019}
}
```
```
@article{chung2019generative,
  title = {Generative pre-training for speech with autoregressive predictive coding},
  author = {Chung, Yu-An and Glass, James},
  journal = {arXiv preprint arXiv:1910.12607},
  year = {2019}
}
```

## Contact
Feel free to shoot me an <a href="mailto:andyyuan@mit.edu">email</a> for any inquiries about the paper and this repository.
